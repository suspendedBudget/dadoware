{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DADOWARE: 2ª edição\n",
    "\n",
    "Foram retiradas palavras ofensivas como \"caboclo\" ou \"nazi\", e outras pouco familiares ou com grafia ibérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nacao', 'nação')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata \n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "def ordem(txt):\n",
    "    txt = txt.lower()\n",
    "    return (shave_marks(txt), txt)\n",
    "\n",
    "ordem('Nação')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import reprlib\n",
    "\n",
    "def mostrar(seq):\n",
    "    print('{} {}'.format(len(seq), reprlib.repr(seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7776 ['a', 'aba', 'abacaxi', 'abade', 'abadia', 'abafado', ...]\n"
     ]
    }
   ],
   "source": [
    "with open('7776palavras.txt', encoding='utf8') as fp:\n",
    "    palavras1 = [p.strip() for p in fp]\n",
    "    \n",
    "mostrar(palavras1) # palavras da 1ª edição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avô']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dup_acentos(palavras):\n",
    "    '''devolve palavras duplicadas diferentes só por terem acentos'''\n",
    "    dup = []  \n",
    "    vistas = set()\n",
    "    for palavra in sorted(palavras, key=ordem):\n",
    "        sem_ac = shave_marks(palavra)\n",
    "        if sem_ac in vistas:\n",
    "            dup.append(palavra)\n",
    "        else:\n",
    "            vistas.add(sem_ac)\n",
    "    return dup\n",
    "        \n",
    "dup_acentos(['alvo', 'avião', 'avó', 'avô'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_acentos(palavras1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, ['abate', 'abdome', 'abdómen'], ['zanga', 'zangado', 'zombar'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../private/sources/2016-06-remove.txt', encoding='utf8') as fp:\n",
    "    texto = fp.read().replace('\\n', ',').replace(';', ',')\n",
    "    tirar = sorted([p.strip() for p in texto.split(',') if len(p.strip()) > 1], key=ordem)\n",
    "    \n",
    "len(tirar), tirar[:3], tirar[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, ['abacate', 'abdome', 'abril'], ['tigre', 'touro', 'vatapá'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../private/sources/2016-06-add.txt', encoding='utf8') as fp:\n",
    "    texto = fp.read().replace('\\n', ',').replace(';', ',')\n",
    "    botar = sorted([p.strip() for p in texto.split(',') if len(p.strip()) > 1], key=ordem)\n",
    "    \n",
    "len(botar), botar[:3], botar[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-298"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_palavras = set(palavras1) - set(tirar)\n",
    "set_palavras |= set(botar)\n",
    "len(set_palavras) - 6**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 ['abraçar', 'acórdão', 'acúmulo', 'aguçado', 'alcácer', 'algodão', ...]\n"
     ]
    }
   ],
   "source": [
    "with open('fontes/candidatas.txt', encoding='utf8') as fp:\n",
    "    candidatas7 = [p.strip() for p in fp]\n",
    "    \n",
    "mostrar(candidatas7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 ['abertura', 'absoluto', 'acidente', 'adiantar', 'adquirir', 'advogado', ...]\n"
     ]
    }
   ],
   "source": [
    "with open('fontes/candidatas-len8.txt', encoding='utf8') as fp:\n",
    "    candidatas8 = [p.strip() for p in fp]\n",
    "    \n",
    "mostrar(candidatas8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7478, 7777)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidatas = set(candidatas7) | set(candidatas8)\n",
    "len(set_palavras), len(set_palavras | candidatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7776    7777   55166 7776palavras-2e.txt\r\n"
     ]
    }
   ],
   "source": [
    "palavras2 = sorted(set_palavras | candidatas, key=ordem)\n",
    "with open('7776palavras-2e.txt', 'wt', encoding='utf8') as fp:\n",
    "    fp.write('\\n'.join(palavras2))\n",
    "    \n",
    "! wc 7776palavras-2e.txt    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "dados5 = list(''.join(dados) for dados in itertools.product('123456', repeat=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7776   15552   86264 dadoware.txt\r\n"
     ]
    }
   ],
   "source": [
    "dadoware = list(zip(dados5, palavras2))\n",
    "with open('dadoware.txt', 'wt', encoding='utf8') as fp:\n",
    "    for indice, palavra in dadoware:\n",
    "        linha = '{} {}\\n'.format(indice[2:], palavra)\n",
    "        fp.write(linha)\n",
    "    \n",
    "!wc dadoware.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
